{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3+6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stc\\Documents\\GitHub\\PredictiveAnalyticsPython\\vkprog_analyse\n",
      "C:\\Users\\stc\\Documents\\GitHub\\PredictiveAnalyticsPython\n"
     ]
    }
   ],
   "source": [
    "# make imports from pa_lib possible (parent directory of file's directory)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "file_dir = Path.cwd()\n",
    "print(file_dir)\n",
    "parent_dir = file_dir.parent\n",
    "print(parent_dir)\n",
    "sys.path.append(str(parent_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pa_lib.data import (boxplot_histogram)\n",
    "\n",
    "from pa_lib.file import (\n",
    "    project_dir,\n",
    "    load_bin,\n",
    "    load_csv,\n",
    "    load_xlsx,\n",
    "    store_bin\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pa_lib.data import desc_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:44:18 [INFO] [ipykernel_launcher.py] requests 'ek_info_prepare.py'\n",
      "11:44:18 [INFO] [ipykernel_launcher.py]: Running job 'ek_info_prepare.py': Run result is out of date ('Today')\n"
     ]
    }
   ],
   "source": [
    "# Lazy Recursive Job Dependency Request:\n",
    "from pa_lib.job import request_job\n",
    "\n",
    "########################################################################################\n",
    "## Recursive Dependency Check:\n",
    "request_job(job_name=\"ek_info_prepare.py\", current= \"Today\") # output: ek_info.feather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset (Data Preparation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vkprog_data_prep import bd_train_scoring\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.whatweekisit.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Wall time: 38.5 s\n",
    "\n",
    "# 2019-10-21 => Calendar week 43\n",
    "(training_all, scoring_all, feature_colnames_bd, feature_colnames_dates,feature_colnames_branchen) = bd_train_scoring(\n",
    "    day=1,\n",
    "    month=7,\n",
    "    year_score=2019,\n",
    "    year_train=2018,\n",
    "    year_span=4,\n",
    "    sales_filter=False, ## Schmeisst gewisse Kunden direkt raus. (Hat nix mit Annulationen zu tun)\n",
    "    scale_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\ntraining_all\\n\")\n",
    "display(training_all.describe())\n",
    "print(\"\\nscoring_all\\n\")\n",
    "display(scoring_all.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(training_all.columns == scoring_all.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for NULLS\n",
    "display(desc_col(training_all)\n",
    "        .sort_values(\"NULLS\", ascending=False)\n",
    "        .head(5)\n",
    "        )\n",
    "\n",
    "display(desc_col(scoring_all)\n",
    "        .sort_values(\"NULLS\", ascending=False)\n",
    "        .head(5)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#desc_col(training_all.loc[:,feature_colnames_branchen])\n",
    "#desc_col(scoring_all.loc[:,feature_colnames_branchen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = training_all\n",
    "print(\"Target_Res_flg == False\")\n",
    "boxplot_histogram(temp_df.loc[ temp_df.Target_Res_flg == False ,\"Erste_Buchung_Delta\"])\n",
    "print(\"Target_Res_flg == True\")\n",
    "boxplot_histogram(temp_df.loc[ temp_df.Target_Res_flg == True ,\"Erste_Buchung_Delta\"])\n",
    "\n",
    "print(\"Target_Res_flg == False\")\n",
    "boxplot_histogram(temp_df.loc[ temp_df.Target_Res_flg == False ,\"Letzte_Buchung_Delta\"])\n",
    "print(\"Target_Res_flg == True\")\n",
    "boxplot_histogram(temp_df.loc[ temp_df.Target_Res_flg == True ,\"Letzte_Buchung_Delta\"])\n",
    "\n",
    "\n",
    "print(\"Target_Res_flg == False\")\n",
    "boxplot_histogram(temp_df.loc[ temp_df.Target_Res_flg == False ,\"Erste_Letzte_Buchung_Delta\"])\n",
    "print(\"Target_Res_flg == True\")\n",
    "boxplot_histogram(temp_df.loc[ temp_df.Target_Res_flg == True ,\"Erste_Letzte_Buchung_Delta\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vkprog_crm_prep  import crm_train_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(crm_train_df, crm_score_df,feature_colnames_crm) = crm_train_scoring(\n",
    "    day=1,\n",
    "    month=7,\n",
    "    year_score=2019,\n",
    "    year_train=2018,\n",
    "    year_span=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pa_lib.data import desc_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_crm_add2master(master_df,crm_df,feature_colnames_crm):\n",
    "    \n",
    "    container_df = pd.merge(master_df, crm_df,how=\"left\", on=\"Endkunde_NR\")\n",
    "\n",
    "    for col_name in list(np.compress(['RY'== x[0:2] for x in feature_colnames_crm],feature_colnames_crm)):\n",
    "        container_df.loc[:,col_name] = container_df.loc[:,col_name].fillna(0)\n",
    "        max_ = np.nanmax(container_df.loc[:,col_name])\n",
    "        min_ = np.nanmin(container_df.loc[:,col_name])\n",
    "        if min_ == max_:\n",
    "            container_df.loc[:,col_name] = 0\n",
    "        else:\n",
    "            container_df.loc[:,col_name] = (container_df.loc[:,col_name] - min_)/(max_ - min_)\n",
    "\n",
    "    for col_name in list(np.compress(['Letzter'== x[0:7] for x in feature_colnames_crm],feature_colnames_crm)):\n",
    "        max_ = np.nanmax(container_df.loc[:,col_name]) # those who have never been contacted will be put together with the max-ones.\n",
    "        container_df.loc[:,col_name] = container_df.loc[:,col_name].fillna(max_) # No more NaNs!\n",
    "        min_ = np.nanmin(container_df.loc[:,col_name])\n",
    "        \n",
    "        if max_ == min_:\n",
    "            container_df.loc[:,col_name] = 1\n",
    "        else:\n",
    "            container_df.loc[:,col_name] = container_df.loc[:,col_name]/max_ # scaling, doesn't need 0\n",
    "    \n",
    "    return container_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_all = scaling_crm_add2master(master_df            = training_all,\n",
    "                                          crm_df               = crm_train_df,\n",
    "                                          feature_colnames_crm = feature_colnames_crm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_all  = scaling_crm_add2master(master_df=scoring_all, crm_df=crm_score_df,feature_colnames_crm=feature_colnames_crm)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "for x in feature_colnames_crm:\n",
    "    print(x)\n",
    "    boxplot_histogram(container_df.loc[:,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in feature_colnames_crm:\n",
    "    boxplot_histogram(training_all.loc[:,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#desc_col(__training_all__).sort_values(\"NULLS\",ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#desc_col(__scoring_all__).sort_values(\"NULLS\",ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_all.shape)\n",
    "print(scoring_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Columns: Features versus Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "features = feature_colnames_bd + feature_colnames_dates + feature_colnames_branchen + feature_colnames_crm\n",
    "#feature_columns = list(compress(features,[\"Target\" not in s for s in features]))\n",
    "\n",
    "feature_columns_boolean = pd.Series(features).str.match('^Target')\n",
    "feature_columns = pd.Series(features).loc[~feature_columns_boolean]\n",
    "\n",
    "feature_columns_boolean = pd.Series(training_all.columns).str.match('^Target')\n",
    "target_columns = pd.Series(training_all.columns).loc[feature_columns_boolean]\n",
    "\n",
    "del feature_columns_boolean\n",
    "\n",
    "#target_columns  = list(compress(training_all.columns,[\"Target\" in s for s in training_all.columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(feature_columns))\n",
    "print(target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[\"Target\" not in s for s in features]\n",
    "#features\n",
    "#display(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split ``training_all`` into training-set (``X_train``,``y_train``) and test-set (``X_test``,``y_test``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = training_all.loc[:,feature_columns].to_numpy()\n",
    "df_target   = training_all.loc[:, \"Target_Res_flg\"].to_numpy()\n",
    "\n",
    "df_scoring_features = scoring_all.loc[:,feature_columns].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_features.shape)\n",
    "print(df_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    #df_features, df_target, train_size=0.80, random_state=42)\n",
    "    df_features, df_target, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)\n",
    "print(\"\\ndf_scoring_features\", df_scoring_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "print('y_train:')\n",
    "print(pd.DataFrame(y_train).groupby(0)[0].count())\n",
    "print(stats.describe(y_train))\n",
    "\n",
    "print('\\ny_test:')\n",
    "print(pd.DataFrame(y_test).groupby(0)[0].count())\n",
    "print(stats.describe(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "#ros = RandomOverSampler(random_state=42)\n",
    "sm  = SMOTE(random_state=42)\n",
    "\n",
    "X_train_balanced, y_train_balanced = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('y_train_balanced:')\n",
    "print(pd.DataFrame(y_train_balanced).groupby(0)[0].count())\n",
    "print(stats.describe(y_train_balanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection: SelectkBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``SelectPercentile`` removes all but a user-specified highest scoring percentage of features.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif # ANOVA F-value\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Wall time: 54 s\n",
    "\n",
    "# use f_classif (the default) and SelectPercentile to select 50% of features\n",
    "\"\"\"\n",
    "select = SelectPercentile(score_func=mutual_info_classif,\n",
    "                          percentile=100)\n",
    "\"\"\"\n",
    "select = SelectKBest(score_func=mutual_info_classif,\n",
    "            k=150 # How many features? (currently 219 is max)\n",
    "            )\n",
    "select.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "mask = select.get_support() # boolean array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train_balanced.shape: {}\".format(X_train_balanced.shape))\n",
    "print(\"X_train_balanced[:,mask].shape: {}\".format(X_train_balanced[:,mask].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns  = feature_columns.loc[mask]\n",
    "X_train_balanced = X_train_balanced[:,mask]\n",
    "X_train          = X_train[:,mask]\n",
    "X_test           = X_test[:,mask]\n",
    "X_scoring        = df_scoring_features[:,mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_scoring:\",X_scoring.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Logistic Regression (base model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Wall time: 1min 13s\n",
    "logreg_C1000 = LogisticRegression(n_jobs=-1,\n",
    "                               solver=\"sag\",\n",
    "                               max_iter=100000,\n",
    "                               C=1000 #adjustable, bigger mean less restriction on coefficients\n",
    "                              ).fit(X_train_balanced, y_train_balanced) # bigger C\n",
    "\n",
    "print(\"Training set score: {:.3f}\".format(logreg_C1000.score(X_train_balanced, y_train_balanced)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg_C1000.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Wall time: 543 ms\n",
    "logreg_C0001 = LogisticRegression(n_jobs=-1,\n",
    "                               solver=\"sag\",\n",
    "                               max_iter=100000,\n",
    "                               C=0.001 #adjustable, bigger mean less restriction on coefficients\n",
    "                              ).fit(X_train_balanced, y_train_balanced) # bigger C\n",
    "\n",
    "print(\"Training set score: {:.3f}\".format(logreg_C0001.score(X_train_balanced, y_train_balanced)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg_C0001.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Plot: Compare LogReg-coefficients for different C (1000, 0.001)\n",
    "plt.figure(figsize=(70,10))\n",
    "plt.grid()\n",
    "plt.plot(logreg_C0001.coef_.T, '^', label=\"C=0.001\")\n",
    "plt.plot(logreg_C1000.coef_.T,    'o', label=\"C=1000\")\n",
    "plt.xticks(range(len(feature_columns)), feature_columns, rotation=90)\n",
    "plt.hlines(0, 0, len(feature_columns))\n",
    "plt.ylim(min(logreg_C1000.coef_.T), max(logreg_C1000.coef_.T))\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Coefficient magnitude\")\n",
    "plt.legend()\n",
    "plt.savefig('this_is_a_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(data={'feature': pd.Series(feature_columns), \n",
    "                             'C1000': list(logreg_C1000.coef_.T),\n",
    "                            'C0001': list(logreg_C0001.coef_.T)})\n",
    "test_df = test_df.sort_values(by=['C1000']).reset_index()\n",
    "\n",
    "# %% Plot: Compare LogReg-coefficients for different C (1000, 0.001)\n",
    "plt.figure(figsize=(70,10))\n",
    "plt.grid()\n",
    "plt.plot(test_df.loc[:,'C0001'], '^', label=\"C=0.001\")\n",
    "plt.plot(test_df.loc[:,'C1000'], 'o', label=\"C=1000\")\n",
    "plt.xticks(range(len(feature_columns)), test_df.loc[:,'feature'], rotation=90)\n",
    "plt.hlines(0, 0, len(feature_columns))\n",
    "plt.ylim(min(logreg_C1000.coef_.T), max(logreg_C1000.coef_.T))\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Coefficient magnitude\")\n",
    "plt.legend()\n",
    "plt.savefig('this_is_a_test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Wall time: 13min\n",
    "forest_01 = RandomForestClassifier(n_estimators=5*10**3,\n",
    "                                max_depth=10,\n",
    "                                criterion='gini',  #criterion='gini',\n",
    "                                random_state=42,\n",
    "                                n_jobs=-1)\n",
    "forest_01.fit(X_train_balanced, y_train_balanced)\n",
    "#forest_01.fit(X_train, y_train)\n",
    "\n",
    "#forest_01.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# %% Validate Accuracy\n",
    "print(\"Accuracy on balanced training set: {:.3f}\".format(forest_01.score(X_train_balanced,y_train_balanced)))\n",
    "print(\"Accuracy on unbalanced training set: {:.3f}\".format(forest_01.score(X_train,y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest_01.score(X_test,     y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Plot: Feature importance\n",
    "def plot_feature_importances(model,feature_columns,figsize=(20,100)):\n",
    "    from operator import itemgetter\n",
    "    dict_feature_importance = sorted(dict(zip(feature_columns,model.feature_importances_)).items(), key=itemgetter(1))\n",
    "    n_features              = len(feature_columns)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.grid()\n",
    "    plt.barh(np.arange(n_features),\n",
    "             [y for (x,y) in dict_feature_importance],\n",
    "             align='center')\n",
    "    plt.yticks(np.arange(n_features), [x for (x,y) in dict_feature_importance])\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(forest_01,feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def confusion_matrices(X_test,y_test):\n",
    "    global pred_forest_01, pred_logreg_C0001, pred_logreg_C1000\n",
    "    \n",
    "    pred_forest_01          = forest_01.predict(X_test)\n",
    "    pred_logreg_C0001       = logreg_C0001.predict(X_test)\n",
    "    pred_logreg_C1000       = logreg_C1000.predict(X_test)\n",
    "\n",
    "\n",
    "    # Wall time: 20.9ms\n",
    "\n",
    "    confusion_logreg_C0001       = confusion_matrix(y_test, pred_logreg_C0001)\n",
    "    df_confusion_logreg_C0001    = pd.DataFrame(confusion_logreg_C0001, index=[\"Fact 0\", \"Fact 1\"], columns=[\"Pred 0\",\"Pred 1\"])\n",
    "\n",
    "    confusion_logreg_C1000       = confusion_matrix(y_test, pred_logreg_C1000)\n",
    "    df_confusion_logreg_C1000    = pd.DataFrame(confusion_logreg_C1000, index=[\"Fact 0\", \"Fact 1\"], columns=[\"Pred 0\",\"Pred 1\"])\n",
    "\n",
    "    confusion_forest_01          = confusion_matrix(y_test, pred_forest_01)\n",
    "    df_confusion_forest_01       = pd.DataFrame(confusion_forest_01, index=[\"Fact 0\", \"Fact 1\"], columns=[\"Pred 0\",\"Pred 1\"])\n",
    "\n",
    "    print(\"Test set balance:\")\n",
    "    print(pd.Series(y_test).value_counts())\n",
    "\n",
    "    print(\"\\nConfusion Matrices:\")\n",
    "\n",
    "    print(\"\\nRandom Forest (forest_01):\")\n",
    "    display(df_confusion_forest_01)\n",
    "\n",
    "    print(\"\\nLogistic Regression C=0.001:\")\n",
    "    display(df_confusion_logreg_C0001)\n",
    "\n",
    "    print(\"\\nLogistic Regression C=1000:\")\n",
    "    display(df_confusion_logreg_C1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices(X_train_balanced,y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $Precision =\\frac{TP}{TP+FP}$\n",
    "2. $Recall =\\frac{TP}{TP+FN}$ <-- Optimising target!\n",
    "3. $f_{1} = 2 \\cdot \\frac{precision \\cdot recall}{precision + recall} = \\frac{2 \\cdot TP}{2 \\cdot TP + (FN + FP)}$\n",
    "4. $Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$ KPI combines Precision and Recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Wall time: 9.94ms\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Logistic Regression C=0.001:\")\n",
    "print(classification_report(y_test,\n",
    "                            pred_logreg_C0001,\n",
    "                            target_names=[\"not booking = 0\", \"booking = 1\"]))\n",
    "\n",
    "print(\"Logistic Regression C=1000:\")\n",
    "print(classification_report(y_test,\n",
    "                            pred_logreg_C1000,\n",
    "                            target_names=[\"not booking = 0\", \"booking = 1\"]))\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(classification_report(y_test,\n",
    "                            pred_forest_01,\n",
    "                            target_names=[\"not booking = 0\", \"booking = 1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_C1000.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def prec_rec_values(X_test,y_test):\n",
    "    global precision_forest_01, recall_forest_01, thresholds_forest_01, precision_logreg_C0001, recall_logreg_C0001, thresholds_logreg_C0001,precision_logreg_C1000, recall_logreg_C1000, thresholds_logreg_C1000 \n",
    "    \n",
    "    # LogReg C=0.001\n",
    "    precision_logreg_C0001, recall_logreg_C0001, thresholds_logreg_C0001 = precision_recall_curve(\n",
    "        y_test, \n",
    "        logreg_C0001.predict_proba(X_test)[:,1])\n",
    "    \n",
    "    # LogReg C=1000\n",
    "    precision_logreg_C1000, recall_logreg_C1000, thresholds_logreg_C1000 = precision_recall_curve(\n",
    "        y_test, \n",
    "        logreg_C1000.predict_proba(X_test)[:,1])\n",
    "    \n",
    "    # RandomForestClassifier has predict_proba, but not decision_function\n",
    "    precision_forest_01, recall_forest_01, thresholds_forest_01 = precision_recall_curve(\n",
    "        y_test,\n",
    "        forest_01.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Wall time: 22.4s\n",
    "\n",
    "def prec_rec_curve(X_train,y_train):\n",
    "    prec_rec_values(X_train,y_train)\n",
    "\n",
    "    plt.figure(figsize=(15,12))\n",
    "    plt.grid()\n",
    "\n",
    "    def optimum_point(precision_forest_01,recall_forest_01,thresholds_forest_01,name,dot):\n",
    "        optimum_idx = pd.Series.idxmin(np.power(1-pd.Series(precision_forest_01),2)+np.power(1-pd.Series(recall_forest_01),2))\n",
    "        return plt.plot(precision_forest_01[optimum_idx],\n",
    "                     recall_forest_01[optimum_idx],\n",
    "                     dot,\n",
    "                     markersize=10,\n",
    "                     label=f\"{name}: threshold {thresholds_forest_01[optimum_idx]}\",\n",
    "                     fillstyle=\"none\",\n",
    "                     c='k',\n",
    "                     mew=2)\n",
    "\n",
    "    optimum_point(precision_forest_01,recall_forest_01,thresholds_forest_01,name=\"forest_01\",dot='o')\n",
    "    optimum_point(precision_logreg_C0001,recall_logreg_C0001,thresholds_logreg_C0001,name=\"logreg_C0001\",dot='x')\n",
    "    optimum_point(precision_logreg_C1000,recall_logreg_C1000,thresholds_logreg_C1000,name=\"logreg_C1000\",dot='+')\n",
    "\n",
    "    plt.plot(precision_logreg_C0001, recall_logreg_C0001, label=\"Logistic Regression, C=0.001\")\n",
    "    plt.plot(precision_logreg_C1000, recall_logreg_C1000, label=\"Logistic Regression, C=1000\")\n",
    "    plt.plot(precision_forest_01, recall_forest_01, label=\"Random Forest\")\n",
    "\n",
    "    plt.xlabel(\"Precision\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_rec_curve(X_train_balanced,y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_rec_curve(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_rec_curve(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot_histogram(thresholds_logreg_C0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Wall time: 19.7 s\n",
    "\n",
    "from sklearn.metrics import average_precision_score # Area under the Recall/Precision-curves\n",
    "\n",
    "avg_precision_logreg_C0001 = average_precision_score(y_test,\n",
    "                                               logreg_C0001.predict_proba(X_test)[:, 1])\n",
    "\n",
    "avg_precision_logreg_C1000 = average_precision_score(y_test,\n",
    "                                               logreg_C1000.predict_proba(X_test)[:, 1])\n",
    "\n",
    "avg_precision_forest_01 = average_precision_score(y_test,\n",
    "                                               forest_01.predict_proba(X_test)[:, 1])\n",
    "\n",
    "\n",
    "print(\"Average Precision of LogReg C=0.001: {:.3f}\".format(avg_precision_logreg_C0001))\n",
    "print(\"Average Precision of LogReg C=1000:  {:.3f}\".format(avg_precision_logreg_C1000))\n",
    "print(\"Average Precision of forest_01:      {:.3f}\".format(avg_precision_forest_01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receiver Operating Characteristics (ROC) and AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.metrics import roc_curve\n",
    "def roc_curve_graph(X_test,y_test):\n",
    "    global fpr_logreg_C0001, tpr_logreg_C0001, thresholds_logreg_C0001, fpr_logreg_C1000, tpr_logreg_C1000, thresholds_logreg_C1000, fpr_forest_01, tpr_forest_01, thresholds_forest_01\n",
    "    fpr_logreg_C0001, tpr_logreg_C0001, thresholds_logreg_C0001 = roc_curve(y_test, logreg_C0001.predict_proba(X_test)[:, 1])\n",
    "    fpr_logreg_C1000, tpr_logreg_C1000, thresholds_logreg_C1000 = roc_curve(y_test, logreg_C1000.predict_proba(X_test)[:, 1])\n",
    "    fpr_forest_01, tpr_forest_01, thresholds_forest_01 = roc_curve(y_test, forest_01.predict_proba(X_test)[:, 1])\n",
    "\n",
    "    def threshold_dot_50perc(fpr_forest_01,tpr_forest_01,thresholds_forest_01,name,dot):\n",
    "\n",
    "        close_default_index_forest_01 = pd.Series.idxmin(np.power(1-pd.Series(tpr_forest_01),2)+np.power(pd.Series(fpr_forest_01),2))\n",
    "        return plt.plot(fpr_forest_01[close_default_index_forest_01], tpr_forest_01[close_default_index_forest_01],\n",
    "                 dot,\n",
    "                 markersize=10,\n",
    "                 label=f\"{name} threshold: {thresholds_forest_01[close_default_index_forest_01]}\",\n",
    "                 fillstyle=\"none\",\n",
    "                 c='k',\n",
    "                 mew=2)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(15,12))\n",
    "    plt.grid()\n",
    "\n",
    "    plt.plot(fpr_forest_01,fpr_forest_01, linestyle='dotted', label=\"base line\")\n",
    "\n",
    "    plt.plot(fpr_logreg_C0001, tpr_logreg_C0001, label=\"logreg_C0001\")\n",
    "    plt.plot(fpr_logreg_C1000, tpr_logreg_C1000, label=\"logreg_C1000\")\n",
    "    plt.plot(fpr_forest_01,    tpr_forest_01,    label=\"forest_01\")\n",
    "\n",
    "\n",
    "    plt.xlabel(\"False-Postive Rate (FPR)\")\n",
    "    plt.ylabel(\"True-Positive Rate (TPR) aka. Recall\")\n",
    "\n",
    "    # find threshold closest to zero\n",
    "    threshold_dot_50perc(fpr_forest_01,tpr_forest_01,     thresholds_forest_01,'forest_01',dot='^')\n",
    "    threshold_dot_50perc(fpr_logreg_C0001, tpr_logreg_C0001, thresholds_logreg_C0001,'logreg_C0001',dot='x')\n",
    "    threshold_dot_50perc(fpr_logreg_C1000,tpr_logreg_C1000,thresholds_logreg_C1000,'logreg_C1000',dot='+')\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Wall time: 17.6s\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def roc_auc(X_test,y_test):\n",
    "    forest_01_auc    = roc_auc_score(y_test,    forest_01.predict_proba(X_test)[:, 1])\n",
    "    logreg_C0001_auc = roc_auc_score(y_test, logreg_C0001.predict_proba(X_test)[:, 1])\n",
    "    logreg_C1000_auc = roc_auc_score(y_test, logreg_C1000.predict_proba(X_test)[:, 1])\n",
    "\n",
    "\n",
    "    print(\"AUC for forest_01:    {:.3f}\".format(forest_01_auc))\n",
    "    print(\"AUC for logreg_C0001: {:.3f}\".format(logreg_C0001_auc))\n",
    "    print(\"AUC for logreg_C1000: {:.3f}\".format(logreg_C1000_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Wall time: 10.6 s\n",
    "roc_curve_graph(X_train_balanced,y_train_balanced)\n",
    "roc_auc(X_train_balanced,y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Wall time: 10.6 s\n",
    "roc_curve_graph(X_train,y_train)\n",
    "roc_auc(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "roc_curve_graph(X_test,y_test)\n",
    "roc_auc(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive feature elimination with cross-validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "# Wall time: 2h 35min 26s\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "svc = SVC(kernel=\"linear\")\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2),\n",
    "              scoring='accuracy')\n",
    "rfecv.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@santiagof/model-interpretability-making-your-model-confess-shapley-values-5fb95a10a624"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "#Wall time: OVER9000!!!\n",
    "#shap_values = shap.TreeExplainer(forest_01).shap_values(X_train_balanced)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#shap.summary_plot(shap_values, X_train_balanced, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Class Probabilities (Booking: No/Yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_prob     = forest_01.predict_proba(X_scoring)\n",
    "scoring_prob_df  = pd.DataFrame(scoring_prob, columns=[\"Prob_0\",\"Prob_1\"])\n",
    "scoring_all_prob = (pd.merge(scoring_all,\n",
    "                             scoring_prob_df,\n",
    "                             left_index=True,\n",
    "                             right_index=True\n",
    "                            ).sort_values(\"Prob_1\",ascending=False)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_all_prob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup for comparision with Rscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_scorings_df =  scoring_all_prob.loc[:,[\"Endkunde_NR\",\"Prob_1\"]]\n",
    "\n",
    "with project_dir(\"vkprog\\\\predictions\"):\n",
    "    store_bin(backup_scorings_df, \"20190701_pred_rebuild.feather\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding additional information for delivery lists ``EK_LIST_2W_KOMPLETT.csv``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pa_lib.file import load_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek_info = load_bin(\"vkprog\\\\ek_info.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek_list_raw = pd.merge(scoring_all_prob,ek_info,on=\"Endkunde_NR\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek_list_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check _col_selection_ in file \"vp2xlsx.py\". It's the only one that actually counts! Compare with R-code to figure out the meaning.\n",
    "\n",
    "net_columns = [col for col in ek_info.columns if col.startswith(\"Net_\")]\n",
    "\n",
    "col_row_filter =([\n",
    "    \"Insolvenz\",\n",
    "    \"Last_Res_Date\",\n",
    "    \"Last_Aus_Date\",\n",
    "    \"last_CRM_Ktkt_date\",\n",
    "    \"VB_FILTER_VON\",\n",
    "    \"VB_FILTER_BIS\"\n",
    "    ])\n",
    "\n",
    "listing = (\n",
    "    [\"Endkunde_NR\",      # Endkunde_NR\n",
    "     \"Endkunde\",         # Endkunde\n",
    "     \"EK_HB_Apg_Kurzz\",  # HB_APG (based on R-script)\n",
    "     \"Agentur\",          # Agentur\n",
    "     \"AG_Hauptbetreuer\", # HB_Agentur   \n",
    "     \"PLZ\",              # PLZ\n",
    "     \"GEMEINDE\"]        # Ort\n",
    "    \n",
    "     +net_columns       # Net_2015, Net_2016, Net_2017, Net_2018, Net_2019 \n",
    "    \n",
    "     +[\"letzte_VBs\",     # (bd, aggregiert)\n",
    "       \"Letzter_Kontakt\", # KZ_letzter_Ktkt (crm)\n",
    "       \"Kanal\",           #(crm)\n",
    "       \"Betreff\",         #(crm)    \n",
    "       \"Last_Res_Date\", # Letzte_Kamp_erfasst\n",
    "       \"Last_Aus_Date\", # letzte_Kamp_Beginn\n",
    "       \"VERKAUFS_GEBIETS_CODE\", # Verkaufsgebiet\n",
    "       \"VB_VKGEB\",      \n",
    "       \"Prob_1\"        # prob_KW (from here, good good.)\n",
    "       ]\n",
    "    # Needed for row_filter\n",
    "    + col_row_filter\n",
    "    )\n",
    "\n",
    "ek_list = (ek_list_raw\n",
    "    .loc[:,listing]\n",
    "    .rename(columns={\n",
    "        \"EK_HB_Apg_Kurzz\": \"HB_APG\",\n",
    "        \"AG_Hauptbetreuer\": \"HB_Agentur\",\n",
    "        \"GEMEINDE\": \"Ort\",\n",
    "        \"Letzter_Kontakt\": \"letzter_Kontakt\",\n",
    "        \"Last_Res_Date\": \"letzte_Kamp_erfasst\",\n",
    "        \"Last_Aus_Date\":\"letzte_Kamp_Beginn\",\n",
    "        \"VERKAUFS_GEBIETS_CODE\": \"Verkaufsgebiet\",\n",
    "        \"VB_VKGEB\": \"VB_VK_Geb\",\n",
    "        \"Prob_1\": \"prob_KW\"\n",
    "    })       \n",
    "    )\n",
    "\n",
    "ek_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek_list.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pauschale Filterkriterien (muss rüber ins vp2xlsx.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_columns = [col for col in ek_info.columns if col.startswith(\"Net_\")] # Net_2015, ..., Net_2019\n",
    "pauschale_filter = (\n",
    "    # Insolvenz:\n",
    "    (ek_info.loc[:,\"Insolvenz\"] \n",
    "         != True\n",
    "    ) &\n",
    "    \n",
    "    # kuerzlich_gebucht (in den letzten 2 Monaten erfasste Kampagnen):\n",
    "    (ek_info.loc[:,\"Last_Res_Date\"] \n",
    "        < pd.Timestamp.now() - pd.DateOffset(months=2)\n",
    "    ) &\n",
    "    \n",
    "    # kuerzlich_im_aushang (Aushangbeginn vor 1 Monat oder später):\n",
    "    (ek_info.loc[:,\"Last_Aus_Date\"] \n",
    "        < pd.Timestamp.now() - pd.DateOffset(months=1)\n",
    "    ) &\n",
    "    \n",
    "    # keine Kleinkunden (Ueber die letzten 4 Jahre nie mehr als 3'000 pro Jahr):\n",
    "    (ek_info.loc[:,net_columns].max(axis=1).fillna(0) \n",
    "        > 3000\n",
    "    ) &\n",
    "    \n",
    "    # keine Neukunden (Alle, die erst im aktuellen Jahr Umsatz hatten):\n",
    "    ((ek_info.loc[:,sorted(net_columns, reverse=True)[1:]]\n",
    "             .max(axis=1)\n",
    "             .fillna(0))\n",
    "        > 0\n",
    "    ) &\n",
    "    \n",
    "    # Umsatz_erreicht (80% Netto-Umsatz gem. Vorjahr erreicht) \n",
    "    ((ek_info.loc[:,sorted(net_columns, reverse=True)[0]]\n",
    "             .fillna(0))\n",
    "         <= 0.8*(ek_info.loc[:,sorted(net_columns, reverse=True)[1]]\n",
    "                        .fillna(0))\n",
    "    ) &\n",
    "    \n",
    "    # kuerzlich_im_kontakt (keine Kunden, mit CRM-Kontakt in den letzten 4 Wochen)\n",
    "    (ek_info.loc[:,\"last_CRM_Ktkt_date\"].fillna(pd.Timestamp.now() - pd.DateOffset(years=100)) \n",
    "        < pd.Timestamp.now() - pd.DateOffset(months=1)\n",
    "    ) &\n",
    "    \n",
    "    # VB_FILTER_AKTIV (in CRM ist eine gültige Sperre für Kunden erfasst)\n",
    "     ~(# We define the evil ones, and take the boolean opposite:\n",
    "    \n",
    "         # Both entries exist: Customer is right now within \"Sperre\"\n",
    "        ((ek_info.loc[:,\"VB_FILTER_VON\"] < pd.Timestamp.now()) &\n",
    "         (pd.Timestamp.now() <= ek_info.loc[:,\"VB_FILTER_BIS\"]))\n",
    "\n",
    "        |# No end date, but begin date exists: \n",
    "        ((ek_info.loc[:,\"VB_FILTER_VON\"] < pd.Timestamp.now()) &\n",
    "         (ek_info.loc[:,\"VB_FILTER_BIS\"].isna() ))\n",
    "\n",
    "        |# No begin date, but end date exists:\n",
    "        (ek_info.loc[:,\"VB_FILTER_VON\"].isna() & \n",
    "         (ek_info.loc[:,\"VB_FILTER_BIS\"] <= pd.Timestamp.now() )) \n",
    "      )\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek_list_pauschale_filter = ek_list.loc[pauschale_filter,:]\n",
    "ek_list_pauschale_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek_list_pauschale_filter.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutoff: Selecting the customers with the highest chances for a sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reality Check: \\nThat's how many last year made reservations in these calendar weeks:\")\n",
    "training_all.groupby(\"Target_Res_flg\").agg({\"Endkunde_NR\": \"count\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the distribution to define a reasonable cut-off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_histogram(ek_list_pauschale_filter.loc[:,\"prob_KW\"])\n",
    "ek_list_pauschale_filter.loc[:,\"prob_KW\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutoff_by_quantile(dataframe, quantile=0.25):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        - Dataframe with Probabilities for a reservation\n",
    "        - Quantile\n",
    "    \n",
    "    Output:\n",
    "        - Subset of initial dataframe cutoff via defined Quantile\n",
    "    \"\"\"\n",
    "    quantile_75      = dataframe.prob_KW.quantile([quantile]).iloc[0]\n",
    "    filter_col       = (dataframe.loc[:,\"prob_KW\"] > quantile_75)\n",
    "    dataframe_cutoff = dataframe.loc[filter_col,:]\n",
    "    print(f\"Dataset: {dataframe_cutoff.shape[0]} out of {dataframe.shape[0]} selected\")\n",
    "    print(f\"Cutoff:  {quantile_75} (minimum predicted probability for a reservation)\")\n",
    "    return dataframe_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek_list_cutoff = cutoff_by_quantile(dataframe=ek_list_pauschale_filter,quantile=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data for tomorrow or so..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#desc_col(ek_list_cutoff)\n",
    "ek_list_cutoff.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek_list_cutoff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek_list_cutoff.to_excel(\"20191104_rebuild_sales.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mu_in = mutual_info_classif(X_train_balanced,y_train_balanced) / mutual_info_classif(y_train_balanced.reshape(-1,1),y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mu_in.shape)\n",
    "print(feature_columns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " mu_in_df = (pd.DataFrame({'Feature':            feature_columns,\n",
    "                           'Mutual_Information': mu_in})\n",
    "             .sort_values(by='Mutual_Information',\n",
    "                          ascending=False)\n",
    "             .reset_index(drop=True)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mu_in_df.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_histogram(mu_in_df.loc[:,'Mutual_Information'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_in_cutoff(cutoff):\n",
    "    display(mu_in_df.loc[mu_in_df.loc[:,'Mutual_Information'] >= cutoff,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_in_cutoff(0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_in_df['scaled'] = mu_in_df['Mutual_Information'] / mu_in_df['Mutual_Information'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_in_df['cum'] = mu_in_df['scaled'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,50))\n",
    "sns.barplot(x   = 'Mutual_Information',\n",
    "            y   = 'Feature',\n",
    "            data= mu_in_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feature_columns:\n",
    "    print(feature)\n",
    "    print(len(training_all.loc[training_all.loc[:,feature] > 0, feature]))\n",
    "    boxplot_histogram(training_all.loc[training_all.loc[:,feature] > 0, feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_all.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hexbin(dataset, first_feature,second_feature,gridsize=25):\n",
    "    dataset.plot.hexbin(x=first_feature, y=second_feature , gridsize=gridsize, figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hexbin(x, y, color, **kwargs):\n",
    "    cmap = sns.light_palette(color, as_cmap=True)\n",
    "    plt.hexbin(x, y, gridsize=10, cmap=cmap, **kwargs)\n",
    "\n",
    "with sns.axes_style(\"dark\"):\n",
    "    g = sns.FacetGrid(training_all,\n",
    "                      hue=\"Target_Res_flg\",\n",
    "                      col=\"Target_Res_flg\",\n",
    "                      height=10\n",
    "                     )\n",
    "\n",
    "g.map(hexbin,\n",
    "      \"Netto_Sum_Aus_RY_0_KW_1\",\n",
    "      \"Erste_Buchung_Delta\",\n",
    "      extent=[0, 1, 0, 1]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sns.axes_style(\"darkgrid\")\n",
    "\n",
    "sns.pairplot(data   = training_all.loc[:,[\"Target_Res_flg\"]+list(mu_in_df.head(20).loc[:,\"Feature\"])],\n",
    "             diag_kind=\"kde\",\n",
    "             hue    = \"Target_Res_flg\",\n",
    "             height =5\n",
    "            ).savefig(\"derp.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
