{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make imports from pa_lib possible (parent directory of file's directory)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "file_dir = Path.cwd()\n",
    "parent_dir = file_dir.parent\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import NamedTuple\n",
    "\n",
    "from pa_lib.file import (\n",
    "    project_dir,\n",
    "    load_bin,\n",
    "    load_pickle,\n",
    "    load_xlsx,\n",
    "    store_bin,\n",
    ")\n",
    "from pa_lib.data import as_dtype, dtFactor, lookup, desc_col, chi2_expected\n",
    "from pa_lib.util import cap_words, collect, value, normalize_rows, as_percent, flatten\n",
    "\n",
    "# display long columns completely, show more rows\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:19:19 [INFO] Started loading binary file ...\n",
      "17:19:19 [INFO] Reading from file C:\\Users\\kpf\\data\\axinova\\ax_data.feather\n",
      "17:19:19 [INFO] ... finished loading binary file in 0.31s (0.98s CPU)\n",
      "17:19:19 [INFO] Started loading pickle file ...\n",
      "17:19:19 [INFO] Reading from file C:\\Users\\kpf\\data\\axinova\\spr_data.pkl\n",
      "17:19:19 [INFO] ... finished loading pickle file in 0.03s (0.03s CPU)\n",
      "17:19:19 [INFO] Started loading pickle file ...\n",
      "17:19:19 [INFO] Reading from file C:\\Users\\kpf\\data\\axinova\\time_code_ratios.pkl\n",
      "17:19:19 [INFO] ... finished loading pickle file in 0.01s (0.0s CPU)\n",
      "17:19:19 [INFO] Started loading pickle file ...\n",
      "17:19:19 [INFO] Reading from file C:\\Users\\kpf\\data\\axinova\\station_code_ratios.pkl\n",
      "17:19:19 [INFO] ... finished loading pickle file in 0.0s (0.0s CPU)\n",
      "17:19:19 [INFO] Started loading pickle file ...\n",
      "17:19:19 [INFO] Reading from file C:\\Users\\kpf\\data\\axinova\\global_code_ratios.pkl\n",
      "17:19:19 [INFO] ... finished loading pickle file in 0.0s (0.0s CPU)\n",
      "17:19:19 [INFO] Started loading pickle file ...\n",
      "17:19:19 [INFO] Reading from file C:\\Users\\kpf\\data\\axinova\\population_ratios.pkl\n",
      "17:19:19 [INFO] ... finished loading pickle file in 0.0s (0.0s CPU)\n"
     ]
    }
   ],
   "source": [
    "with project_dir(\"axinova\"):\n",
    "    ax_data = load_bin(\"ax_data.feather\")\n",
    "    spr_data = load_pickle(\"spr_data.pkl\")\n",
    "    time_codes = load_pickle(\"time_code_ratios.pkl\")\n",
    "    station_codes = load_pickle(\"station_code_ratios.pkl\")\n",
    "    global_codes = load_pickle(\"global_code_ratios.pkl\")\n",
    "    population_codes = load_pickle(\"population_ratios.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look up code ratios from axinova data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RatioTable = pd.DataFrame\n",
    "Ratios = NamedTuple(\"Ratios\", ((\"actual\", RatioTable), (\"expected\", RatioTable)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ax_global_ratios(variable: str, percent: bool = False) -> RatioTable:\n",
    "    ratios = global_codes.query(\"Variable == @variable\").pivot_table(\n",
    "        values=\"Ratio\", index=\"Variable\", columns=\"Code\"\n",
    "    )\n",
    "    return as_percent(ratios) if percent else ratios\n",
    "\n",
    "\n",
    "def ax_station_ratios(variable: str, percent: bool = False) -> Ratios:\n",
    "    actual_ratios = station_codes.query(\"Variable == @variable\").pivot_table(\n",
    "        values=\"Ratio\", index=\"Station\", columns=\"Code\", fill_value=0\n",
    "    )\n",
    "    expected_ratios = ax_global_ratios(variable)\n",
    "    if percent:\n",
    "        result = Ratios(as_percent(actual_ratios), as_percent(expected_ratios))\n",
    "    else:\n",
    "        result = Ratios(actual_ratios, expected_ratios)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ax_ratios(\n",
    "    variable: str,\n",
    "    stations: str,\n",
    "    reference: str = \"all_stations\",\n",
    "    time_scale: str = \"Hour\",\n",
    "    percent: bool = False,\n",
    ") -> Ratios:\n",
    "    subset = ax_data.loc[\n",
    "        ax_data.Station.isin(flatten(stations)) & (ax_data.Variable == variable)\n",
    "    ]\n",
    "    full_index = [\n",
    "        (weekday, time)\n",
    "        for weekday in ax_data[\"DayOfWeek\"].cat.categories\n",
    "        for time in ax_data[time_scale].cat.categories\n",
    "    ]\n",
    "    actual_counts = subset.pivot_table(\n",
    "        values=\"Value\", index=[\"DayOfWeek\", time_scale], columns=\"Code\", fill_value=0,\n",
    "    )\n",
    "    actual_ratios = normalize_rows(actual_counts).reindex(full_index, fill_value=0)\n",
    "\n",
    "    if reference == \"all_stations\":\n",
    "        expected_ratios = (\n",
    "            time_codes[time_scale]\n",
    "            .query(\"Variable == @variable\")\n",
    "            .pivot_table(\n",
    "                values=\"Ratio\",\n",
    "                index=[\"DayOfWeek\", time_scale],\n",
    "                columns=\"Code\",\n",
    "                fill_value=0,\n",
    "            )\n",
    "        )\n",
    "    elif reference == \"station\":\n",
    "        expected_counts = chi2_expected(actual_counts)\n",
    "        expected_ratios = normalize_rows(expected_counts).reindex(\n",
    "            full_index, fill_value=0\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Parameter 'reference' must be one of ('station', 'all_stations'), was '{reference}'\"\n",
    "        )\n",
    "\n",
    "    if percent:\n",
    "        result = Ratios(as_percent(actual_ratios), as_percent(expected_ratios))\n",
    "    else:\n",
    "        result = Ratios(actual_ratios, expected_ratios)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look up SPR+ data split by variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spr_split(\n",
    "    stations,\n",
    "    variable,\n",
    "    reference=\"station\",\n",
    "    time_scale=\"Hour\",\n",
    "    type=\"abs\",\n",
    "):\n",
    "    if type not in [\"abs\", \"rel\"]:\n",
    "        raise ValueError(\n",
    "            f\"Parameter 'type' must be one of ('abs', 'rel'), was '{type}'\"\n",
    "        )\n",
    "    if reference not in [\"station\", \"all_stations\"]:\n",
    "        raise ValueError(\n",
    "            f\"Parameter 'reference' must be one of ('station', 'all_stations'), was '{reference}'\"\n",
    "        )\n",
    "\n",
    "    spr_counts = (\n",
    "        spr_data.loc[spr_data.Station.isin(flatten(stations))]\n",
    "        .groupby([\"DayOfWeek\", time_scale])[[\"Total\"]]\n",
    "        .agg(\"sum\")\n",
    "    )\n",
    "    ratios = ax_ratios(\n",
    "        stations=stations, variable=variable, reference=reference, time_scale=time_scale\n",
    "    )\n",
    "    if type == \"abs\":\n",
    "        code_ratios = ratios.actual\n",
    "    elif type == \"rel\":\n",
    "        code_ratios = ratios.actual - ratios.expected\n",
    "    result = code_ratios.mul(spr_counts.Total, axis=\"index\").round(0).astype(\"int\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Station ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with value(ax_station_ratios(variable=\"g_220\", percent=True)) as autobesitz:\n",
    "    display(autobesitz.actual)\n",
    "    display(autobesitz.expected)\n",
    "    display(autobesitz.actual.sub(autobesitz.expected.values, axis=\"columns\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time ratios for one station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with value(ax_ratios(stations=\"Lausanne\", variable=\"g_220\")) as lausanne_auto:\n",
    "    display(lausanne_auto.actual)\n",
    "    display(lausanne_auto.expected)\n",
    "    display(lausanne_auto.actual - lausanne_auto.expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPR+ data for one station split by ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with value((\"Bern\", \"g_220\", \"Hour\")) as (stat, var, scale):\n",
    "    display(spr_split(stations=stat, variable=var, type=\"abs\", time_scale=scale))\n",
    "    display(spr_split(stations=stat, variable=var, type=\"rel\", time_scale=scale))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
